{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator as ESE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import evaluation\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_similarity.csv', usecols=[\"Describe_1\", \"Describe_2\", \"Similarity_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df.duplicated().sum())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_positive = df[df['Similarity_score'] >= 0.7]\n",
    "train_df_positive, temp_df_positive = train_test_split(movie_positive, test_size=0.2, random_state=42)\n",
    "valid_df_positive, test_df_positive = train_test_split(temp_df_positive, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_negative = df[df['Similarity_score'] <= 0.3].sample(n=1000000, random_state=42)\n",
    "train_df_negative, temp_df_negative = train_test_split(movie_negative, test_size=0.2, random_state=42)\n",
    "valid_df_negative, test_df_negative = train_test_split(temp_df_negative, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_hard_negative = df[(df['Similarity_score'] > 0.3) & (df['Similarity_score'] < 0.7)].sample(n=1000000, random_state=42)\n",
    "train_df_hard_negative, temp_df_hard_negative = train_test_split(movie_hard_negative, test_size=0.2, random_state=42)\n",
    "valid_df_hard_negative, test_df_hard_negative = train_test_split(temp_df_hard_negative, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df_positive, train_df_hard_negative, train_df_negative])\n",
    "valid_df = pd.concat([valid_df_positive, valid_df_hard_negative, valid_df_negative])\n",
    "test_df = pd.concat([test_df_positive, test_df_hard_negative, test_df_negative])\n",
    "\n",
    "train_df = train_df.sample(frac=1, random_state=42)\n",
    "valid_df = valid_df.sample(frac=1, random_state=42)\n",
    "test_df = test_df.sample(frac=1, random_state=42)\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(\"../data/data_train.parquet\", engine=\"fastparquet\", index=False)\n",
    "valid_df.to_parquet(\"../data/data_valid.parquet\", engine=\"fastparquet\", index=False)\n",
    "test_df.to_parquet(\"../data/data_test.parquet\", engine=\"fastparquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"../data/data_train.parquet\")\n",
    "valid_df = pd.read_parquet(\"../data/data_valid.parquet\")\n",
    "test_df = pd.read_parquet(\"../data/data_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBERTDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sentences1 = df['Describe_1'].tolist()\n",
    "        self.sentences2 = df['Describe_2'].tolist()\n",
    "        self.similarity = df['Similarity_score'].tolist()  # Nhãn\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.similarity)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"sentence_features\": [self.sentences1[idx], self.sentences2[idx]],\n",
    "            \"label\": torch.tensor(self.similarity[idx], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "class WeightedSimilarityMSELoss(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.loss_fct = nn.MSELoss(reduction='none')  # 'none' để giữ giá trị loss cho từng sample\n",
    "        self.model = model  \n",
    "\n",
    "    def forward(self, sentence_features, labels):\n",
    "        # Tokenize danh sách các câu\n",
    "        tokenized = self.model.tokenizer(\n",
    "            list(sentence_features[0]) + list(sentence_features[1]),  # Ghép hai danh sách câu\n",
    "            padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(self.model.device)  # Đưa vào GPU nếu có\n",
    "\n",
    "        # Lấy embeddings từ transformer model\n",
    "        output = self.model(tokenized)\n",
    "        embeddings = output['sentence_embedding']  # Chứa embeddings của cả hai danh sách câu\n",
    "\n",
    "        # Chia thành embeddings1 và embeddings2\n",
    "        embeddings1, embeddings2 = embeddings.chunk(2, dim=0)\n",
    "\n",
    "        # Tính cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(embeddings1, embeddings2, dim=-1)\n",
    "\n",
    "        # Tính loss MSE giữa cosine similarity và nhãn thực tế\n",
    "        loss = self.loss_fct(cos_sim, labels.to(self.model.device))\n",
    "\n",
    "        # Áp dụng trọng số dựa trên nhãn\n",
    "        weights = torch.ones_like(labels).to(self.model.device)\n",
    "        weights[labels <= 0.3] = 1.5\n",
    "        weights[(labels > 0.3) & (labels < 0.7)] = 1.5\n",
    "        weights[labels >= 0.7] = 50\n",
    "\n",
    "        # Nhân trọng số vào loss\n",
    "        weighted_loss = loss * weights\n",
    "\n",
    "        return weighted_loss.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SBERTDataset(train_df)\n",
    "val_data = SBERTDataset(valid_df)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "\n",
    "val_examples = [\n",
    "    InputExample(texts=[val_data[i][\"sentence_features\"][0], val_data[i][\"sentence_features\"][1]], \n",
    "                 label=val_data[i][\"label\"].item())  # .item() để chuyển tensor thành số thực\n",
    "    for i in range(len(val_data))\n",
    "]# Chuyển thành list\n",
    "val_evaluator = ESE.from_input_examples(val_examples, name=\"val\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "train_loss = WeightedSimilarityMSELoss(model)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}\")\n",
    "\n",
    "    for batch in epoch_iterator:\n",
    "        batch_labels = batch[\"label\"] \n",
    "        # Chia batch thành 2 danh sách riêng biệt\n",
    "        batch_sentences = batch[\"sentence_features\"]  # Chuyển tuple thành list\n",
    "        sentences1 = list(batch_sentences[0]) \n",
    "        sentences2 = list(batch_sentences[1])\n",
    "\n",
    "        batch_sentences = (sentences1, sentences2)\n",
    "\n",
    "        # Tính loss\n",
    "        loss = train_loss(batch_sentences, batch_labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Cập nhật thanh tiến trình\n",
    "        epoch_iterator.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Đánh giá sau mỗi epoch\n",
    "    model.eval()\n",
    "    val_evaluator(model, output_path=\"../model/fine_tuned_sbert_movies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo Evaluator cho tập test\n",
    "# test_evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(test_data, name=\"test\")\n",
    "\n",
    "# test_score = test_evaluator(model)\n",
    "# print(f\"Test Evaluation Score: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie1_embeddings = model.encode(test_data[\"Movie_1\"].tolist(), convert_to_tensor=True)\n",
    "# movie2_embeddings = model.encode(test_data[\"Movie_2\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# # Tính cosine similarity giữa movie1 & movie2\n",
    "# cosine_similarities = torch.nn.functional.cosine_similarity(movie1_embeddings, movie2_embeddings).cpu().numpy()\n",
    "\n",
    "# # Giá trị thực tế từ tập test\n",
    "# true_scores = test_data[\"Similarity_score\"].values\n",
    "\n",
    "# # Đánh giá bằng MSE và Pearson correlation\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# mse = mean_squared_error(true_scores, cosine_similarities)\n",
    "# pearson_corr, _ = pearsonr(true_scores, cosine_similarities)\n",
    "\n",
    "# print(f\" Mean Squared Error (MSE): {mse:.4f}\")\n",
    "# print(f\" Pearson Correlation: {pearson_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
